2. K-Means Clustering Algorithm
ğŸ” What is K-Means?
K-Means is an unsupervised clustering algorithm that partitions data into K non-overlapping clusters.

Each data point belongs to the cluster with the nearest mean (centroid).

âš™ï¸ Steps of K-Means:
Choose the number of clusters (K).

Initialize K centroids randomly.

Assign each data point to the nearest centroid (based on Euclidean distance).

Update centroids by calculating the mean of all points in each cluster.

Repeat steps 3â€“4 until centroids do not change significantly (convergence).

kmeans = KMeans(n_clusters=3)
kmeans.fit(X)
n_clusters=3: We expect 3 natural clusters (as there are 3 species in the dataset).

fit(X): Runs the K-means algorithm on the feature data X.

ğŸ“Œ Key Terms:
Centroids: Mean positions of each cluster.

Labels: Assigned cluster ID (0, 1, or 2) for each sample.

ğŸ“ˆ 3. Visualization

plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
Plots the first two features (for simplicity) of each point.

Colors them by their cluster labels (c=labels).

plt.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=200, c='red')
Marks the cluster centroids with red "X" symbols.

ğŸ§  Unsupervised Learning Context
Unlike supervised learning:

There is no ground truth or target y.

The algorithm finds patterns or groupings in the data based on similarity.

Useful for exploratory data analysis, customer segmentation, etc.

ğŸ“Š Evaluation (Not in Code)
Because it's unsupervised, accuracy metrics like in classification don't directly apply. Common evaluation methods include:

Inertia: Sum of squared distances to the closest cluster center.

Silhouette score: Measures how well each point fits into its cluster vs others.

Comparing labels with ground truth (if known): e.g., via confusion matrix or adjusted Rand index.